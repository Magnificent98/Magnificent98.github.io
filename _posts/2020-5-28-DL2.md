---
layout: post
title: Deep Learning(II)
category: Deep Learning
date: 2020-5-28
---

# 了解神经网络的大致结构以及工作原理之后，来看一下神经网络的调优。

## 1. 初始化，正则化与梯度校验
<p>&nbsp;&nbsp; 想要得到一个表现良好的神经网络，不能仅仅建好框架然后给他塞数据，还有很多很多的细节要照顾到。其实建立一个网络结构反而是比较简单的，各种参数，超参数的调整才是精华所在。先从初始化，正则化，梯度校验方面简述。 </p><br/>

### 1.1 训练集，验证集，测试集

| | 训练集 | 验证集 | 测试集 |
|---|---|---|---|
| 目的 | 训练数据 | 验证网络结构的合理性 | 测试网络结构的效果 |
|---|---|---|---|
| 占比(小型数据集) | 60%左右 | 20%左右 | 20%左右 |
|---|---|---|---|
| 占比(大型数据集) | 99.8%左右 | 0.1%左右 | 0.1%左右|

<br/>
<p>&nbsp;&nbsp; 拿到一个数据集首先要进行分类，可以分成训练集，验证集，测试集，也可以将验证集和测试集合一。在训练集部分对数据进行训练，在验证集部分对网络进行调参，或直接尝试不同的网络，在测试集验证网络的表现效果。 </p><br/>

### 1.2 偏差与方差

| | 偏差 | 方差 | 贝叶斯误差 |
|---|---|---|---|
|定义 | 模型在训练集上的误差 | 模型在训练集与验证集上误差的差值 | 理论上的最小误差(误差天花板) |

<br/>

e.g.<br/>

| 贝叶斯误差 约等于 0 | | | | |
|---|---|---|---|---|
| 训练集 | 1% | 15% | 15% | 0.5% |
| 验证集 | 11% | 16% | 30% | 1% |
|---|---|---|---|---|
| 表现 | 误差小，方差大，可能发生过拟合 | 误差大，方差小，网络预测精度低 | 误差大，方差大。| 误差小，方差小，完美可用 |

<br/>

### 1.3 参数初始化
<p>&nbsp;&nbsp; 之前提到过，深层网络的参数不能初始化为零。应用randn()初始化为符合标准正态分布的随机数，通常还要让他们变得比较小(根据激活函数)。这样一方面可以利用激活函数较大的导数值加快学习效率，另一方面可以防止梯度爆炸。但是初始化也不能太小，否则在反向传播的时候，会发生梯度消失。下面用例子证明合理初始化的重要性。 </p><br/>

使用上一章最后实现的多层网络结构

```python
# 初始化为0
def initialize_parameters_deep(layers_dims):
    '''
    Args:
        layers_dims: list that contains num of neurons on each layer

    Returns:
        well initialized parameters
        {"W1": W1 matrix, "b1": b1 matrix, ...}
    '''
    parameters = {}
    L = len(layers_dims)

    for l in range(1, L):
        # initialize to zero
        parameters["W{}".format(l)] = np.zeros((layers_dims[l], layers_dims[l-1]))
        parameters["b{}".format(l)] = np.zeros((layers_dims[l], 1))

    return parameters
# 训练集准确度：65.55023923444976%
# 测试集准确度：34.0%
```

对应的loss图如下：
<div align="center">
<img src="{{site.url}}{{site.baseurl}}{{site.assets_path}}/img/deeplearning/II_1.png" width="50%" height="50%"/>
</div>

<br/>

```python
# 初始化为随机数
def initialize_parameters_deep(layers_dims):
    '''
    Args:
        layers_dims: list that contains num of neurons on each layer

    Returns:
        well initialized parameters
        {"W1": W1 matrix, "b1": b1 matrix, ...}
    '''
    parameters = {}
    L = len(layers_dims)

    for l in range(1, L):
        # initialize to random numbers
        parameters["W{}".format(l)] = np.random.randn(layers_dims[l], layers_dims[l-1])
        parameters["b{}".format(l)] = np.zeros((layers_dims[l], 1))

    return parameters
# 学习失败 因为Z值过大，产生了内存溢出
```

<br/>

```python
# 抑梯度异常初始化
def initialize_parameters_deep(layers_dims):
    '''
    Args:
        layers_dims: list that contains num of neurons on each layer

    Returns:
        well initialized parameters
        {"W1": W1 matrix, "b1": b1 matrix, ...}
    '''
    parameters = {}
    L = len(layers_dims)

    for l in range(1, L):
        # a good initialize for relu activation function
        # he_norm
        parameters["W{}".format(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * np.sqrt(2 / layers_dims[l-1])
        parameters["b{}".format(l)] = np.zeros((layers_dims[l], 1))

    return parameters
# 训练集准确度：98.08612440191388%
# 测试集准确度：74.0%
```

对应的loss图如下：
<div align="center">
<img src="{{site.url}}{{site.baseurl}}{{site.assets_path}}/img/deeplearning/II_2.png" width="50%" height="50%"/>
</div>

<br/><br/>

### 1.4 正则化模型
<p>&nbsp;&nbsp; 正则化模型解决的问题是过拟合。当训练数据较少，或者训练过度的时候，模型会发生过拟合，表现为在训练集上效果很好，但是在验证集上效果很差。一般发生过拟合是模型被一些点“带偏”了，或过分依赖于某些神经单元。解决过拟合的方法是引入正则化。 </p><br/>

#### 1.4.1 L2正则化
<p>&nbsp;&nbsp; L2正则化的原理是，总把weight控制在一个比较小的范围内，又称weight decay，这样有些节点可以忽略不记，就把一个复杂的模型简单化了。而过拟合的模型确实是过度复杂的，需要一些简化。</p><br/>

$$
J(W^{[L]},b^{[L]}) = \frac{1}{m}\sum_{i=1}^{m}L(A^{i}, Y^{i}) + \frac{\lambda}{2m}\sum_{l=1}^{L}||W^{[l]}||^{2}\;(||W^{[l]}||^2=\sum_i \sum_j (W_{i,j}^{[l]})^2)
\\
则dW^{[l]} = (from backprop) + \frac{\lambda}{m}W^{[l]}
\\
即W^{[l]} = W^{[l]}-\alpha dW^{[l]}=(1-\frac{\alpha \lambda}{m})W^{[l]} - \alpha (from backprop)
$$

<br/>
<p>&nbsp;&nbsp; 可见L2正则化在每一步更新权重的时候，缩减了权重的大小. 这里lamda是一个超参数,可以自行调整. </p><br/>

```python
def compute_cost(AL, Y, lamda, params):
    '''
    Args:
        AL: predicted values
        Y: labeled values

    Returns:
        the cost: cross entropy loss
    '''
    L = len(params) // 2
    sum = 0
    for l in range(1, L+1):
        sum += np.sum(np.square(params["W{}".format(l)]))
    # batch num
    m = Y.shape[1]
    # cost with L2 regularization
    cost = -np.sum(np.multiply(np.log(AL), Y) + np.multiply(np.log(1 - AL), 1 - Y)) / m + \
           lamda / (2*m) * sum
    # to make sure cost is a num
    cost = np.squeeze(cost)

    return cost


def linear_activation_backward(dA, cache, activation, lamda):
    linear_cache, activation_cache = cache
    if activation == 'relu':
        dZ = relu_backward(dA, activation_cache)
        dA_prev, dW, db = linear_backward(dZ, linear_cache)
        # L2 regularization
        dW += lamda / dA.shape[1] * linear_cache[1]
    else:
        dZ = sigmoid_backward(dA, activation_cache)
        dA_prev, dW, db = linear_backward(dZ, linear_cache)
        # L2 regularization
        dW += lamda / dA.shape[1] * linear_cache[1]
    return dA_prev, dW, db

# 不使用L2正则化
parameters = L_layers_model(train_x_flatten, train_y, layers_dims, learning_rate=0.01)
# 训练集准确度：100.0%
# 测试集准确度：60%

# 使用L2正则化
parameters = L_layers_model(train_x_flatten, train_y, layers_dims, learning_rate=0.01, lamda=1.5)
#训练集准确度：100.0%
#测试集准确度：74.0%
#方差缩小

```
<br/>

#### 1.4.2 Dropout正则化
<p>&nbsp;&nbsp; 为了使模型复杂度降低,还有一种方法是直接抛弃某些神经单元,在一轮的传播中忽略它.这样做整个系统就不能过分依赖于某一个神经单元,因为在下一轮的传播中很可能它就被抛弃了. 这种方法在解决过拟合中作用很大. </p><br/>

<p>&nbsp;&nbsp; 编程有点复杂哦,这里就略了. 谁让人家有写好的库呢? 要注意的一点是, 使用了dropout, 本层输出要/keepprob, 这样才能保证输出期望不变哦. </p><br/>

### 1.5 梯度校验
<p>&nbsp;&nbsp; 正向传播是比较简单的, 反向传播则比较复杂. 为了验证我们得到的反向传播函数是否正确, 我们需要进行梯度校验. 其步骤如下:</p><br/>

<p>(1.) 将所有的参数列成一个列表.</p><br/>
<p>&nbsp;&nbsp; parameters = {"W1": W1, "b1": b1, "W2": W2, "b2": b2, ...} => [W1.flatten, b1.flatten, W2.faltten, ....] </p><br/>
<p>(2.) 选择合适的epsilon, 对列表的每一项进行定义上的求导, 定义如下:</p><br/>

$$
\frac{dJ}{d\theta} = \lim_{e\rightarrow 0}\frac{J(\theta +e)-J(\theta -e)}{2e}
$$

<br/>

<p>(3.) 求得定义上的导数, 与模型算出的导数对比, 小于某个阈值(10e-7)即可认为无误.</p><br/>

$$
difference = \frac{||grad - gradapprox||_2}{||grad||_2+||gradapprox||_2}\\
即空间距离
$$

<br/>

### 1.6 机器学习指南
(1.) 偏差是否高？若是的话尝试更深更大的网络，训练更久的时间。<br/>
(2.) 如果偏差不高，方差是否高？如果是的话，尝试更多的数据，以及正则化方法。<br/>
(3.) 如果偏差方差都不高，那么模型就是一个好模型。<br/>
<br/><br/>

## 2. 优化算法
<p>&nbsp;&nbsp; 优化算法是为了让模型的训练更加迅速。目前为止我们学习到的模型是所有样本一起训练，并且使用简单的梯度下降方法反向传播。为了让模型更加迅速，能处理更大的数据，需要引入新的算法。 </p><br/>

### 2.1 mini-batch gradient decent
<p>&nbsp;&nbsp; 当样本数量非常大的时候(5000,000个)，所有样本一起训练会带来很多计算量。可能一次梯度下降就要计算很久很久。这时我们可以采用小样本先进行一部分梯度下降，就会使整体速度快很多。 </p><br/>

$$
X = [X^{(1)},X^{(2)},X^{(3)},X^{(4)},....X^{(m)}]\;\;\;take\;mini-batch\;size\;as\;4\;for\;instance\\
batch1=[X^{(1)},X^{(2)},X^{(3)},X^{(4)}]\\
batch2=[X^{(5)},X^{(6)},X^{(7)},X^{(8)}]\\
...\\
$$

<br/>

```python
batch_size = 5000,000
mini_batch_size = 1000
batches = batch_size / mini_batch_size = 5000
for t in range(batches):
    forward_prop on Xt
    backward_prop to update weights and bias

# 可见遍历一次整个训练集(一次epoch)会进行5000次梯度下降
```

| batch_size | 特点 |
|---|---|
| m | batch gradient decent, 这样做每一次梯度下降会很费时 |
|---|---|
| 1 | stochastic gradient decent, 这样做每一次梯度下降会很快，但是整体损失曲线噪音很大，且没有充分利用向量化带来的便利 |
|---|---|
|between 1 and m <br/> proper number of 2^n | mini batch gradient decent, 可以在样本数量巨大的情况下获得最快速的学习效果 |

<br/>

下面给出一种实现方法

```python
def random_mini_batches(X, Y, mini_batch_size = 64):
    '''
    Args:
        X: input data
        Y: labeled data
        mini_batch_size:

    Returns:
        a list contains all the mini_batches
    '''
    m = X.shape[1]
    mini_batches = []
    # 在样本数量的维度上打乱排序
    permutation = list(np.random.permutation(m))    # 生成长度为m的随机数组，数字为0~m-1的乱序排列
    shuffled_X = X[:, permutation]
    shuffled_Y = Y[:, permutation].reshape((1, m))
    # 进行切割
    num_of_mini_batches = math.floor(m / mini_batch_size)
    for i in range(num_of_mini_batches):
        mini_batch_X = shuffled_X[:, i * mini_batch_size:(i + 1) * mini_batch_size]
        mini_batch_Y = shuffled_Y[:, i * mini_batch_size:(i + 1) * mini_batch_size]
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)
    # 余下的自成一组
    if m % mini_batch_size != 0:
        mini_batch_X = shuffled_X[:, mini_batch_size * num_of_mini_batches:]
        mini_batch_Y = shuffled_Y[:, mini_batch_size * num_of_mini_batches:]
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)
    return mini_batches

```

<br/>

### 2.2 exponentially weighted averages
<p>&nbsp;&nbsp; 指数加权平均是一种求平均的方法。它将在后面三种优化算法中大展手脚。 </p><br/>

$$
V_0=0 \\
V_1=\beta V_0+(1-\beta)\theta_1 \\
V_2=\beta V_1+(1-\beta)\theta_2 \\
V_3=\beta V_2+(1-\beta)\theta_3 \\
V_4=\beta V_3+(1-\beta)\theta_4 \\
...\\
V_n=\beta V_(n-1)+(1-\beta)\theta_n\\
V_n=(1-\beta)\theta_n+\beta(1-\beta)\theta_(n-1)+\beta^2(1-\beta)\theta_(n-2)+...+\beta^(n-1)(1-\beta)\theta_1\\
$$

<br/>
<p>&nbsp;&nbsp; 在1/(1-beta)项后，beta^t(1-beta)会很接近于0，可以忽略。所以V_t可以看作是综合了大部分前1/(1-beta)项的结果以及小部分当前输入的结果。但是注意到V_1只采用了当前输入的很小一部分(还没有前面的项)，会产生偏差。故引入bias correction。 </p><br/>

$$
V_t=\frac{\beta V_t+(1-\beta)\theta_t}{1-\beta^t}
$$

<br/>

### 2.3 momentum gradient descent
<p>&nbsp;&nbsp; 注意到采用了minibatch以后，梯度下降最大的问题是会产生摇摆。某一个batch某个维度的梯度较大，整个系统就会偏向它。但是这不是我们想要的，我们想要它快速的趋向于整体的最低点。所以就需要参考整个系统的“惯性”，来为当前梯度较大的方向加一点“阻力”，来纠正整个路线，以获得最大的“动量”。那么前面的指数加权平均就要派上用场了。因为每一个值受到当前输入的影响比较小，大部分是之前的趋势，所以就不会被某一个输入带偏。采用了momentum gradient descent之后，我们就可以把学习率加大了。 </p><br/>

$$
compute\;dW,\;db\;on\;current\;minibatch\\
V_{dW}=\beta V_{dW}+(1-\beta)dW\\
V_{db}=\beta V_{db}+(1-\beta)db\\
更新权值照旧\\
$$

实现方法很简单，照抄公式，不再赘述。
<br/>
<br/>

### 2.4 RMSprop
<p>&nbsp;&nbsp; momentum gradient descent已经很好的解决了许多问题。RMSprop从另一个角度出发，也较好的解决了“摇摆”的问题。思路是，如果参数在当前这个维度上变化不大，那么就给他提提速，而如果变化很大的话，就降降速。 </p><br/>

$$
compute\;dW\;db\;on\;current\;minibatch\;\\
S_{dW}=\beta S_{dW}+(1-\beta)dW^2(element-wise)\\
S_{db}=\beta S_{db}+(1-\beta)db^2(elemetn-wise)\\
更新权值\\
W:=W-\alpha \frac{dW}{\sqrt{S_{dW}}+\epsilon}\;\;\;b:=b-\alpha \frac{db}{\sqrt{S_{db}}+\epsilon}\\

$$

<br/>

<p>&nbsp;&nbsp; 如果某一步dW很大的话，说明当前维度上dW变化很快，我们需要给他降降速。dW很大，则dW^2就很大，学习率变成了alpha/sqrt(Sdw)，会变小。而如果dW很小的话，同理。这里分母加epsilon是为了防止分母为0. epsilon一般取10e-8. </p><br/>

### 2.5 Adam
<p>&nbsp;&nbsp; Adam方法并不是Adam发明的，是Adaptive moment estimation的简称。它可谓取了上面两个方法的精华所在，组成了一个更加强大的优化算法。 </p><br/>

$$
compute\;dW\;db\;on\;current\;minibatch\;\\
V_{dW}=\beta_1 V_{dW}+(1-\beta_1)dW\;\;\;V_{db}=\beta_1 V_{db}+(1-\beta_1)db\\
S_{dW}=\beta_2 S_{dW}+(1-\beta_2)dW^2\;\;\;S_{db}=\beta_2 S_{db}+(1-\beta_2)db^2\\
bias\;correction:\\
V^{corrected}_{dW}=\frac{V_{dW}}{1-\beta_1^t}\;\;\;V^{corrected}_{db}=\frac{V_{db}}{1-\beta_1^t}\\
S^{corrected}_{dW}=\frac{S_{dW}}{1-\beta_2^t}\;\;\;S^{corrected}_{db}=\frac{S_{db}}{1-\beta_2^t}\\
更新权值：\\
W:=W-\alpha \frac{V^{corrected}_{dW}}{\sqrt{S^{corrected}_{dW}}+\epsilon}\;\;\;b:=b-\alpha \frac{V^{corrected}_{db}}{\sqrt{S^{corrected}_{db}}+\epsilon}\\

$$

<p>&nbsp;&nbsp; 这里alpha需要调参，而beta1一般用0.9，beta2一般用0.999，epsilon一般用10e-8. </p><br/>

### 2.6 learning rate decay
<p>&nbsp;&nbsp; learning rate decay是在训练初期，使用一个较大的学习率，而在后期使用一个较小的学习率。即先粗调，后细调。因为一开始距离全局最小值是有很大距离的，所以步子跨大一点是没事的，而在后期，如果步子大了容易在全局最小值附近徘徊，无法到达。这时把学习率调小，可以有效帮助损失函数到达全局最小值。下面给出一种实现，实现方式很多。 </p><br/>

$$
\alpha=\frac{1}{1+decayrate*epoch_num}\alpha_0
$$

<br/><br/>

## 3. 归一化

### 3.1 batch normalization
<p>&nbsp;&nbsp; 为了防止梯度爆炸或弥散，提高模型对不同hyperparams的鲁棒性，以及让大部分激活函数远离其饱和区域，我们要使用归一化。 </p><br/>

$$
对于m个样本的输入\\
\mu = \frac{1}{m}\sum_i^m X^{(i)}\;\;\; \sigma^2=\frac{1}{m}\sum_i^m(X^{(i)}-\mu)^2\\
X^{(i)} = \frac{X^{(i)}-\mu}{\sqrt{\sigma^2}+\epsilon}\\
对于网络的每一层\\
\mu 与 \sigma 求得的方法同前\\
Z_{norm}^{(i)}=\frac{Z^{(i)}-\mu}{\sqrt{\sigma^2}+\epsilon}\\
Z^{(i)}=\gamma Z_{norm}^{(i)}+\beta\;\;\; \gamma 以及 \beta 都是可学习参数\\
A^{(i)}=g(Z^{(i)})\;\;\; 先归一化，后激活。
$$

<br/>

<p>&nbsp;&nbsp; Z_norm已经归一化为均值为0，方差为1的标准分布。但是很多情况下，我们并不像让下一层的输入归一化为均值为0，方差为1的分布。所以引入了可学习的参数gamma与beta。同样采用梯度下降的方法进行学习。所以加上了batch norm的计算图是这样的： </p><br/>

$$
X\rightarrow Z_{pre}^{[1]} \rightarrow Z_{normed}^{[1]} \rightarrow A^{[1]} \rightarrow Z_{pre}^{[2]} \rightarrow Z_{normed}^{[2]} \rightarrow A^{[2]}\rightarrow ...\\
parameters:{W^{[1]}, b^{[1]}, \gamma^{[1]}, \beta^{[1]}, W^{[2]}, b^{[2]}, \gamma^{[2]}, \beta^{[2]},...}\\
backprop: to\;caculate\;dW\;db\;d\gamma\;d\beta
$$

<br/>

<p>&nbsp;&nbsp; 现在还有一个问题就是在测试的时候，往往只有一个或者几个测试cases。这样测试样例的归一化怎么做呢？一般是针对不同的mini-batch得出不同的mu与sigma，然后取指数加权平均值，作为输入样本的mu与sigma。不过这些机器学习框架会自动完成，我们就不需要care啦。 </p><br/>

### 3.2 softmax
<p>&nbsp;&nbsp; softmax是一种激活函数，在多分类问题中十分常用。为什么放到归一化里面来说呢？因为它完成的工作也是归一化。一个输入X会产生C种输出结果，代表C个类别。将网络的输出层加上一层softmax，就会输出C个类别各自的概率。softmax之所以是soft，是因为不像hardmax，把输出层数值最大的直接量化成1，其他的量化成0. softmax的计算公式如下： </p><br/>

$$
t_i=e^{Z_i^{[L]}}\;\;\;A_i^{[L]}=\frac{t_i}{\sum_j{t_j}}\\
可见最终的输出层和为1\\
L(A,Y)=-\sum_j Y_jlogA_j\\
J = \frac{1}{m}\sum_{i=1}^mL(A^{(i)}, Y^{(i)})
$$

<br/>