---
layout: post
title: Pytorch and Deep Learning
category: Deep Learning
date: 2020-6-3
---

## 1. Pytorch and Deep Net
<p>&nbsp;&nbsp; 知识点为：两种创建网络的方法，初始化参数方法，训练方法，网络的保存与加载。 </p><br/>

```python
import torch
import torch.nn.functional as F
import torch.nn as nn
import lr_utils
import matplotlib.pyplot as plt
import pylab

# first way of constructing a net
class Net(nn.Module):
    def __init__(self, x_in):
        super(Net, self).__init__()
        self.hidden1 = nn.Linear(x_in, 20)
        self.hidden2 = nn.Linear(20, 7)
        self.hidden3 = nn.Linear(7, 5)
        self.hidden4 = nn.Linear(5, 2)

    def forward(self, X):
        X = F.relu(self.hidden1(X))
        X = F.relu(self.hidden2(X))
        X = F.relu(self.hidden3(X))
        X = self.hidden4(X)

        return X

def predict(test_x, test_y, net):
    predict = net(test_x)
    predict = torch.max(predict, 1)[1]
    print(1 - torch.mean(torch.abs(predict - test_y)))


if __name__ == '__main__':
    # load data, in form of numpy
    train_x_orig, train_y, test_x_orig, test_y, classes = lr_utils.load_dataset()
    train_x_flatten = train_x_orig.reshape((train_x_orig.shape[0], -1)).T / 255
    test_x_flatten = test_x_orig.reshape((test_x_orig.shape[0], -1)).T / 255
    # train_x_tensor: (209, 12288)
    # train_y_tensor: (209)
    # pay attention to data types
    train_x_tensor = torch.tensor(train_x_flatten.T, dtype=torch.float32)
    # labels have only one dimension
    train_y_tensor = torch.tensor(train_y, dtype=torch.int64).squeeze()
    train_y_tensor_test = torch.tensor(train_y, dtype=torch.float32).squeeze()
    test_x_tensor = torch.tensor(test_x_flatten.T, dtype=torch.float32)
    test_y_tensor = torch.tensor(test_y, dtype=torch.float32).squeeze()
    # constructing the net
    net = Net(train_x_tensor.size()[1])
    # the opitimizer
    optimizer = torch.optim.SGD(net.parameters(), lr=0.0075)
    # the loss function
    # cross entrofy loss takes n inputs and interpret them as n choices.
    # corresponding label can be one digit, indicating the choice it made.
    loss_func = nn.CrossEntropyLoss()
    # for ploting
    losses = []

    # initializaiton
    # a good initialization for relu
    for m in net.parameters():
        if isinstance(m, nn.Linear):
            nn.init.kaiming_normal_(m.weight, mode='fan_in')

    # start training
    for i in range(3000):
        # get the prediction
        out = net(train_x_tensor)
        # caculate the loss
        loss = loss_func(out, train_y_tensor)
        losses.append(loss)
        # clear the grads
        optimizer.zero_grad()
        # backprop
        loss.backward()
        # update the parameters
        optimizer.step()

    predict(train_x_tensor, train_y_tensor_test, net)
    predict(test_x_tensor, test_y_tensor, net)
    plt.plot(losses)
    pylab.show()

    #---------------------------------------------------------#
    # second way of constructing a net
    X_in = train_x_tensor.size()[1]
    net2 = nn.Sequential(
        nn.Linear(X_in, 20),
        nn.ReLU(),
        nn.Linear(20, 7),
        nn.ReLU(),
        nn.Linear(7, 5),
        nn.ReLU(),
        nn.Linear(5, 2)
    )
    losses2 = []
    optimizer = torch.optim.SGD(net2.parameters(), lr=0.0075)
    for m in net2.parameters():
        if isinstance(m, nn.Linear):
            nn.init.kaiming_normal_(m.weight, mode='fan_in')
    for i in range(3000):
        out = net2(train_x_tensor)
        loss = loss_func(out, train_y_tensor)
        losses2.append(loss)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    predict(train_x_tensor, train_y_tensor_test, net2)
    predict(test_x_tensor, test_y_tensor, net2)
    plt.plot(losses2)
    pylab.show()


    #---------------------------------------------------------#
    # first way of saving a net(save all, in form of pickle)
    torch.save(net, "net.pkl")
    # second way of saving a net(save state_dict(), in form of pickle)
    torch.save(net2.state_dict(), "net2.pkl")

    # first way of loading a net(corresponding to first way of saving)
    net3 = torch.load("net.pkl")

    # second way of loading a net(corresponding to second way of saving)
    # must construct the net first
    net4 = nn.Sequential(
        nn.Linear(X_in, 20),
        nn.ReLU(),
        nn.Linear(20, 7),
        nn.ReLU(),
        nn.Linear(7, 5),
        nn.ReLU(),
        nn.Linear(5, 2)
    )
    net4.load_state_dict(torch.load("net2.pkl"))

```
<br/>

## 2. DataLoader
<p>&nbsp;&nbsp; DataLoader是pytorch提供的，非常方便的提取数据的工具。我们训练一般在mini-batches上完成，而要想以mini-batches的方式加载数据，就要用到DateLoader。 </p><br/>

```python
import torch
import torch.nn as nn
import torch.utils.data as Data
import lr_utils
import matplotlib.pyplot as plt
import pylab

def predict(net, x, y):
    out = net(x)
    predict = torch.max(out, 1)[1]
    print(1 - torch.mean(torch.abs(predict - y)))

if __name__ == '__main__':
    # get original data and transform into tensors
    train_x_orig, train_y_orig, test_x_orig, test_y_orig, classes = lr_utils.load_dataset()
    train_x_flatten = train_x_orig.reshape((train_x_orig.shape[0], -1)).T / 255
    test_x_flatten = test_x_orig.reshape((test_x_orig.shape[0], -1)).T / 255
    train_x_tensor = torch.tensor(train_x_flatten.T, dtype=torch.float32)
    train_y_tensor = torch.tensor(train_y_orig, dtype=torch.long).squeeze()
    train_y_fortest_tensor = torch.tensor(train_y_orig, dtype=torch.float32).squeeze()
    test_x_tensor = torch.tensor(test_x_flatten.T, dtype=torch.float32)
    test_y_tensor = torch.tensor(test_y_orig, dtype=torch.float32).squeeze()
    # batch size
    batch_size = 64
    x_in = train_x_tensor.size()[1]
    # construct the net
    net = nn.Sequential(
        nn.Linear(x_in, 20),
        nn.ReLU(),
        nn.Linear(20, 7),
        nn.ReLU(),
        nn.Linear(7, 5),
        nn.ReLU(),
        nn.Linear(5, 2)
    )
    # construct the dataset
    dataset = Data.TensorDataset(train_x_tensor, train_y_tensor)
    # construct the dataloader
    # shuffle means to shuffle data in each epoch
    loader = Data.DataLoader(
        dataset=dataset,
        batch_size=batch_size,
        shuffle=True
    )

    optimizer = torch.optim.SGD(net.parameters(), lr=0.0075)
    loss_func = nn.CrossEntropyLoss()
    losses = []
    # start training.
    # for each epoch, there are sample/batch_size times of gradient descent
    for epoch in range(3000):
        for step, (batch_x, batch_y) in enumerate(loader):
            if epoch % 100 == 0:
                print("training on epoch {}  step {}".format(epoch, step))
            out = net(batch_x)
            loss = loss_func(out, batch_y)
            losses.append(loss)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

    predict(net, train_x_tensor, train_y_fortest_tensor)
    predict(net, test_x_tensor, test_y_tensor)
    plt.plot(losses)
    pylab.show()

```

<br/>

## 3. Optimizers
<p>&nbsp;&nbsp; 选择不同的Optimizer可以获得不同的学习速率。Pytorch预置了很多Optimizer，这里配合恩达的课程，只介绍4种，不过也就这4中最常用。 </p><br/>

```python
# 1. SGD(随机梯度下降)
optimizer = torch.optim.SGD(net.parameters(), lr=0.0005)

# 2. Momentum Gradient Descent
optimizer = torch.optim.SGD(net.parameters(), lr=0.0005, momentum=0.9)

# 3. RMSprop
optimizer = torch.optim.RMSprop(net.parameters(), lr=0.0005, alpha=0.9)

# 4. Adam
optimizer = torch.optim.Adam(net.parameters(), lr=0.0005, betas=(0.9, 0.99))

```
<br/>

## 4. Regularization
<p>&nbsp;&nbsp; Regularization解决过拟合问题。主要有两种，dropout与L2. </p><br/>

```python
# 1. dropout
# 数值表示抛弃节点的概率
net = nn.Sequential(
        nn.Linear(x_in, 20),
        nn.Dropout(0.2),
        nn.ReLU(),
        nn.Linear(20, 7),
        nn.Dropout(0.2),
        nn.ReLU(),
        nn.Linear(7, 5),
        nn.Dropout(0.2),
        nn.ReLU(),
        nn.Linear(5, 2)
    )

# 2. L2
# L2正则化在优化器的weight_decay字段体现
# L2的作用其实就是权重衰减
optimizer = torch.optim.Adam(net.parameters(), lr=0.0005, weight_decay=0.06)

# 是不是方便到爆？

```

<br/>

## 5. Batch Norm
<p>&nbsp;&nbsp; 前面说过，batch norm的作用是防止梯度爆炸，梯度弥散，加强模型对超参数的鲁棒性，使输入远离激活函数的饱和区域。 </p><br/>

```python
# batchnorm层夹在Linear与激活函数之间
net = nn.Sequential(
        nn.Linear(x_in, 20),
        nn.BatchNorm1d(20, momentum=0.5),
        nn.ReLU(),
        nn.Linear(20, 7),
        nn.BatchNorm1d(7, momentum=0.5),
        nn.ReLU(),
        nn.Linear(7, 5),
        nn.BatchNorm1d(5, momentum=0.5),
        nn.ReLU(),
        nn.Linear(5, 2)
    )

```
<br/>

## 6. Predict
<p>&nbsp;&nbsp; 训练好参数测试的时候，因为网络中可能采用了dropout等措施，我们要使用.eval()打开网络的测试模式，才能避免测试中也使用dropout带来的精度损失。.train()是训练模式开关，用于在训练过程中，想对验证集进行测试使用.eval()后，进行恢复。 </p><br/>

```python
# 打开测试模式
net.eval()

# 打开训练模式
net.train()

```

<br/>

## 7. 实战

### 7.1 LeNet-5 变种
<p>&nbsp;&nbsp; 这里使用了LeNet-5对手势集合进行辨别。自己调整了一些网络参数。但是卷积+全连接层的结构没有改变。使用默认初始化，添加了batch_norm层，使用Adam算法优化，使用了L2正则化，没有使用dropout。 </p><br/>

<p>&nbsp;&nbsp; 具体结构是，64x64x1的灰度图像经过5x5的卷积核生成60x60x6输出，经过BN，Relu进行步长为2，卷积核大小为2的下采样(MaxPooling)，生成30x30x6的输出。之后再经过5x5的卷积核生成26x26x16的输出，BN，Relu之后继续下采样，生成13x13x16的输出。之后将输出铺平，进入全连接层。全连接层的大小依次为2704x400, 400x120, 120x84, 84x6，接入softmax进行分类。 </p><br/>

```python
import torch
import torch.nn as nn
import torch.utils.data as Data
import matplotlib.pyplot as plt
import pylab
import numpy as np
import tf_utils

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)
        self.bn1 = nn.BatchNorm2d(6)
        self.mx1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
        self.bn2 = nn.BatchNorm2d(16)
        self.mx2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.fc1 = nn.Linear(2704, 400)
        self.bn3 = nn.BatchNorm1d(400)

        self.fc2 = nn.Linear(400, 120)
        self.bn4 = nn.BatchNorm1d(120)

        self.fc3 = nn.Linear(120, 84)
        self.bn5 = nn.BatchNorm1d(84)

        self.fc4 = nn.Linear(84, 6)


    def forward(self, X):
        X = torch.relu(self.bn1(self.conv1(X)))
        X = self.mx1(X)

        X = torch.relu(self.bn2(self.conv2(X)))
        X = self.mx2(X)

        X = X.reshape(X.size()[0], -1)

        X = torch.relu(self.bn3(self.fc1(X)))
        X = torch.relu(self.bn4(self.fc2(X)))
        X = torch.relu(self.bn5(self.fc3(X)))
        X = self.fc4(X)

        return X

def Gray(numpy_img):
    '''
    convert to gray scale image
    '''
    R = numpy_img[:, :, :, 0]
    G = numpy_img[:, :, :, 1]
    B = numpy_img[:, :, :, 2]
    numpy_gray = 0.299 * R + 0.587 * G + 0.114 * B
    numpy_gray = numpy_gray[:, :, :, np.newaxis]
    return numpy_gray



def predict(net, x, y):
    '''
    make predictions to see the performace
    '''
    net.eval()
    out = net(x)
    predict = torch.max(out, 1)[1]
    print(1 - ((predict-y).nonzero().size()[0] / y.size()[0]))


if __name__ == '__main__':
    # get original data (BHWC)
    train_x_orig, train_y_orig, test_x_orig, test_y_orig, classes = tf_utils.load_dataset()
    train_x_orig = Gray(train_x_orig)
    test_x_orig = Gray(test_x_orig)

    # to tensor (BCHW)
    # put the data on GPU
    train_x_tensor = torch.tensor(train_x_orig.reshape \
(train_x_orig.shape[0], train_x_orig.shape[3], train_x_orig.shape[1], train_x_orig.shape[2]),\
dtype=torch.float32).cuda() / 255.0
    train_y_tensor = torch.tensor(train_y_orig, dtype=torch.long).cuda().squeeze()
    test_x_tensor = torch.tensor(test_x_orig.reshape \
(test_x_orig.shape[0], test_x_orig.shape[3], test_x_orig.shape[1], test_x_orig.shape[2]), \
dtype=torch.float32).cuda() / 255.0
    test_y_tensor = torch.tensor(test_y_orig, dtype=torch.long).cuda().squeeze()

    batch_size = 128
    dataset = Data.TensorDataset(train_x_tensor, train_y_tensor)
    loader = Data.DataLoader(
        dataset=dataset,
        batch_size=batch_size,
        shuffle=True
    )

    net = Net().cuda()

    # use Adam with L2 regularization
    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.99), weight_decay=0.01)
    # cross entrofy
    loss_func = nn.CrossEntropyLoss()
    losses = []

    # strat training
    for epoch in range(1000):
        for step, (batch_x, batch_y) in enumerate(loader):
            if epoch % 10 == 0:
                print("epoch: {}".format(epoch))
            out = net(batch_x.cuda())
            loss = loss_func(out, batch_y.cuda())
            losses.append(loss)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    predict(net, train_x_tensor, train_y_tensor)
    predict(net, test_x_tensor, test_y_tensor)
    plt.plot(losses)
    pylab.show()


# finally, the accuracy on training set is 100%
# the accuracy on test set is 93%
# good job

```

### 7.2 ResNet
<p>&nbsp;&nbsp; ResNet是深度网络的一种解决方案。当网络深度加深，经常会出现梯度消失的问题。这样训练误差不降反增。引入残差网络，添加短路层，可以允许网络的层数进一步提升。 </p><br/>

<p>&nbsp;&nbsp; 这个实例是一个50层的深度残差卷积网络，目的是识别手势集。主要采用了两种残差块，一种是前后维度不变的残差块，另一种是前后维度可发生变化的残差块。hyperprams是抄别人的，不得不说，当网络深度加深，卷积核数量变大，是真的很吃资源。在GPU上训练之后，必须搬到CPU上才能进行测试，不然会爆显存。1080个64x64x3的样本，batchsize定为128，训练了50轮。效果很一般，在训练集上有99的准确率，在验证集上有73的准确率，方差过大。不过轮次上升应该能获得更好的效果。 </p><br/>

```python
import torch
import torch.nn as nn
import torch.utils.data as Data
import matplotlib.pyplot as plt
import pylab
import math
import tf_utils


class residual_block(nn.Module):
    '''
    a residual block
    ** the input img must have the same dims as output img

    in_c: in channel
    out_cs: list of num of kernels of each layer.
    kernel_mid: the kernel size of the middel conv layer
    '''
    def __init__(self, in_c, out_cs, kernel_mid):
        super(residual_block, self).__init__()
        self.conv1 = nn.Conv2d(in_c, out_cs[0], kernel_size=1, stride=1, padding=0)
        self.bn1 = nn.BatchNorm2d(out_cs[0])
        self.conv2 = nn.Conv2d(out_cs[0], out_cs[1], kernel_size=kernel_mid, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(out_cs[1])
        self.conv3 = nn.Conv2d(out_cs[1], out_cs[2], kernel_size=1, stride=1, padding=0)
        self.bn3 = nn.BatchNorm2d(out_cs[2])

    def forward(self, X):
        X_short = X
        X = torch.relu(self.bn1(self.conv1(X)))
        X = torch.relu(self.bn2(self.conv2(X)))
        X = self.bn3(self.conv3(X))
        X = torch.relu(X_short + X)
        return X

class conv_res_net(nn.Module):
    '''
    a residual block with conv layer on the short cut.
    when input img and output img have the different dims

    '''
    def __init__(self, in_c, out_cs, kernel_mid, s_first):
        super(conv_res_net, self).__init__()
        self.conv1 = nn.Conv2d(in_c, out_cs[0], kernel_size=1, stride=s_first, padding=0)
        self.bn1 = nn.BatchNorm2d(out_cs[0])
        self.conv2 = nn.Conv2d(out_cs[0], out_cs[1], kernel_size=kernel_mid, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(out_cs[1])
        self.conv3 = nn.Conv2d(out_cs[1], out_cs[2], kernel_size=1, stride=1, padding=0)
        self.bn3 = nn.BatchNorm2d(out_cs[2])
        self.conv4 = nn.Conv2d(in_c, out_cs[2], kernel_size=1, stride=s_first, padding=0)
        self.bn4 = nn.BatchNorm2d(out_cs[2])

    def forward(self, X):
        X_short = X
        X = torch.relu(self.bn1(self.conv1(X)))
        X = torch.relu(self.bn2(self.conv2(X)))
        X = self.bn3(self.conv3(X))
        X_short = self.bn4(self.conv4(X_short))
        X = torch.relu(X_short + X)
        return X


class ResNet(nn.Module):
    def __init__(self, x_in, x_h):
        super().__init__()
        self.zp1 = nn.ZeroPad2d(3)
        x_h += 6

        self.conv1 = nn.Conv2d(x_in, 64, kernel_size=7, stride=2)
        self.bn1 = nn.BatchNorm2d(64)
        self.mp1 = nn.MaxPool2d(kernel_size=3, stride=2)
        x_h = math.floor((x_h-7)/2+1)
        x_h = math.floor((x_h-3)/2+1)

        self.conv_res_block1 = conv_res_net(64, [64, 64, 256], kernel_mid=3, s_first=1)
        self.res_block1 = residual_block(256, [64, 64, 256], kernel_mid=3)
        self.res_block2 = residual_block(256, [64, 64, 256], kernel_mid=3)

        self.conv_res_block2 = conv_res_net(256, [128, 128, 512], kernel_mid=3, s_first=2)
        self.res_block3 = residual_block(512, [128, 128, 512], kernel_mid=3)
        self.res_block4 = residual_block(512, [128, 128, 512], kernel_mid=3)
        self.res_block5 = residual_block(512, [128, 128, 512], kernel_mid=3)
        x_h = math.floor((x_h-1)/2+1)

        self.conv_res_block3 = conv_res_net(512, [256, 256, 1024], kernel_mid=3, s_first=2)
        self.res_block6 = residual_block(1024, [256, 256, 1024], kernel_mid=3)
        self.res_block7 = residual_block(1024, [256, 256, 1024], kernel_mid=3)
        self.res_block8 = residual_block(1024, [256, 256, 1024], kernel_mid=3)
        self.res_block9 = residual_block(1024, [256, 256, 1024], kernel_mid=3)
        self.res_block10 = residual_block(1024, [256, 256, 1024], kernel_mid=3)
        x_h = math.floor((x_h-1)/2+1)

        self.conv_res_block4 = conv_res_net(1024, [512, 512, 2048], kernel_mid=3, s_first=2)
        self.res_block11 = residual_block(2048, [512, 512, 2048], kernel_mid=3)
        self.res_block12 = residual_block(2048, [512, 512, 2048], kernel_mid=3)
        x_h = math.floor((x_h-1)/2+1)

        self.ap1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=math.ceil(x_h/2))
        self.fc1 = nn.Linear(x_h*x_h*2048, 6)


    def forward(self, X):
        X = self.zp1(X)
        X = torch.relu(self.bn1(self.conv1(X)))
        X = self.mp1(X)

        X = self.res_block2(self.res_block1(self.conv_res_block1(X)))
        X = self.res_block5(self.res_block4(self.res_block3(self.conv_res_block2(X))))
        X = self.res_block10(self.res_block9(self.res_block8(self.res_block7(self.res_block6(self.conv_res_block3(X))))))
        X = self.res_block12(self.res_block11(self.conv_res_block4(X)))

        X = self.ap1(X)

        X = X.reshape((X.size()[0], -1))

        X = self.fc1(X)
        return X

def predict(net, x, y):
    net.eval()
    out = net(x)
    predict = torch.max(out, 1)[1]
    print(1 - ((predict-y).nonzero().size()[0] / y.size()[0]))

if __name__ == '__main__':
    train_x_orig, train_y_orig, test_x_orig, test_y_orig, classes = tf_utils.load_dataset()
    train_x_tensor = torch.tensor(train_x_orig.reshape \
(train_x_orig.shape[0], train_x_orig.shape[3], train_x_orig.shape[1], train_x_orig.shape[2]), \
dtype=torch.float32).cuda() / 255.0
    train_y_tensor = torch.tensor(train_y_orig, dtype=torch.long).cuda().squeeze()
    test_x_tensor = torch.tensor(test_x_orig.reshape \
(test_x_orig.shape[0], test_x_orig.shape[3], test_x_orig.shape[1], test_x_orig.shape[2]), \
dtype=torch.float32) / 255.0
    test_y_tensor = torch.tensor(test_y_orig, dtype=torch.long).squeeze()

    batch_size = 128
    dataset = Data.TensorDataset(train_x_tensor, train_y_tensor)
    loader = Data.DataLoader(
        dataset=dataset,
        batch_size=batch_size,
        shuffle=True
    )

    net = ResNet(3, 64).cuda()

    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.99), weight_decay=0.01)
    loss_func = nn.CrossEntropyLoss()
    losses = []

    for epoch in range(50):
        for step, (batch_x, batch_y) in enumerate(loader):
            if epoch % 10 == 0:
                print("epoch: {}".format(epoch))
            out = net(batch_x.cuda())
            loss = loss_func(out, batch_y.cuda())
            losses.append(loss)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    net = net.cpu()
    train_x_tensor = train_x_tensor.cpu()
    train_y_tensor = train_y_tensor.cpu()
    predict(net, train_x_tensor, train_y_tensor)
    predict(net, test_x_tensor, test_y_tensor)
    plt.plot(losses)
    pylab.show()

```

<br/>
